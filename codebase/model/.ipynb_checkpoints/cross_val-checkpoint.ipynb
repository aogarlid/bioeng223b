{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import os, re, and skimage packages to load images\n",
    "import os\n",
    "import re\n",
    "from skimage import io, color\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.io import imread\n",
    "\n",
    "# import numpy, pandas, shutil, and sklearn packages to implenet k-fold cross-validation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# import keras packages to generate model\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import History\n",
    "\n",
    "# import matplot for visualizing training results\n",
    "import matplotlib.pyplot as plt  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "establish expected image parameters, locations, and augmentation procedures\n",
    "'''\n",
    "\n",
    "# establish data directories for training, testing, and validation\n",
    "train_data_dir = '../../data/train'\n",
    "validation_data_dir = '../../data/validation'\n",
    "test_data_dir = '../../data/test'\n",
    "\n",
    "# expected image size\n",
    "img_width, img_height = 512, 512\n",
    "\n",
    "# establish batch size\n",
    "batch_size = 16\n",
    "\n",
    "# establish number of epochs to run\n",
    "epoch = 100\n",
    "\n",
    "# augmentation configuration for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "#        rotation_range=20,\n",
    "        rescale=1./255,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip = True)\n",
    "\n",
    "# augmentation configuration for testing: only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create image generators that will read images found in\n",
    "# subfolders of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        color_mode = 'grayscale',\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        color_mode = 'grayscale',\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "# this is a similar generator, for testing data\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_data_dir,\n",
    "        target_size = (img_width, img_height),\n",
    "        batch_size = 1,\n",
    "        color_mode = 'grayscale',\n",
    "        class_mode = 'binary',\n",
    "        # this will also ensure the same order\n",
    "        shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "build 16-layer VGG ConvNet\n",
    "'''\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(img_width, img_height, 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "plot_model(model, to_file='../../output/models/vgg16_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to run prediction, using the testing data generator function with batch size = 1\n",
    "'''\n",
    "train model and generate history callback\n",
    "'''\n",
    "\n",
    "def train_model(train_generator= train_generator, validation_generator=validation_generator,\n",
    "                validation_samples = validation, train_samples = train, \n",
    "                epoch = epoch, batch_size = batch_size):\n",
    "    history = model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch = train_samples // batch_size,\n",
    "            epochs=epoch,\n",
    "            validation_data = validation_generator,\n",
    "            validation_steps = validation_samples // batch_size,\n",
    "            callbacks=[history])\n",
    "    return history\n",
    "#    weights_filename = '../../output/weights/vgg16_weights_Mar22-730.h5' + i\n",
    "#    model.save_weights('../../output/weights/vgg16_weights_Mar22-730.h5')  # always save your weights after training or during training\n",
    "\n",
    "# create test data generator\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_data_dir,\n",
    "        target_size = (img_width, img_height),\n",
    "        batch_size = 1,\n",
    "        color_mode = 'grayscale',\n",
    "        class_mode = 'binary',\n",
    "        # this will also ensure the same order\n",
    "        shuffle = False)\n",
    "\n",
    "# run prediction generator on test dataset\n",
    "def predict_test(model = model, test_data_dir = test_data_dir, \n",
    "                 img_width = img_width, img_height = img_height, \n",
    "                 total_test_images = total_test_images):\n",
    "    probabilities=model.predict_generator(\n",
    "        test_generator, \n",
    "        steps=total_test_images)\n",
    "\n",
    "# return filenames for testing images for evaluation of predictions\n",
    "image_name=test_generator.filenames\n",
    "probabilities\n",
    "# compare predictions to ground truth and acquire overall prediction accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# used to copy files according to each fold\n",
    "def copy_images(df, directory):\n",
    "    destination_directory = \"../../data/\" + directory\n",
    "    print(\"copying {} files to {}...\".format(directory, destination_directory))\n",
    "\n",
    "    # remove all files from previous fold\n",
    "    if os.path.exists(destination_directory):\n",
    "        shutil.rmtree(destination_directory)\n",
    "\n",
    "    # create folder for files from this fold\n",
    "    if not os.path.exists(destination_directory):\n",
    "        os.makedirs(destination_directory)\n",
    "\n",
    "    # create subfolders for each class\n",
    "    for c in set(list(df['class'])):\n",
    "        if not os.path.exists(destination_directory + '/' + c):\n",
    "            os.makedirs(destination_directory + '/' + c)\n",
    "\n",
    "    # copy files for this fold from a directory holding all the files\n",
    "    for i, row in df.iterrows():\n",
    "        try:\n",
    "            # this is the path to all of your images kept together in a separate folder\n",
    "            path_from = \"../../data/images/\"\n",
    "            path_from = path_from + \"{}.jpg\"\n",
    "            path_to = \"{}/{}\".format(destination_directory, row['class'])\n",
    "\n",
    "            # move from folder keeping all files to training, test, or validation folder (the \"directory\" argument)\n",
    "            shutil.copy(path_from.format(row['filename']), path_to)\n",
    "        except Exception, e:\n",
    "            print(\"Error when copying {}: {}\".format(row['filename'], str(e)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dataframe containing the filenames of the images (e.g., GUID filenames) and the classes\n",
    "df = pd.read_csv('../../data/labels.csv')\n",
    "df_y = df['Label']\n",
    "df_x = df\n",
    "del df_x['Label']\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 10)\n",
    "total_actual = []\n",
    "total_predicted = []\n",
    "total_val_accuracy = []\n",
    "total_val_loss = []\n",
    "total_test_accuracy = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (train_index, test_index) in enumerate(skf.split(df_x, df_y)):\n",
    "    x_train, x_test = df_x.iloc[train_index], df_x.iloc[test_index]\n",
    "    y_train, y_test = df_y.iloc[train_index], df_y.iloc[test_index]\n",
    "\n",
    "    train = pd.concat([x_train, y_train], axis=1)\n",
    "    test = pd.concat([x_test, y_test], axis = 1)\n",
    "\n",
    "    # take 20% of the training data from this fold for validation during training\n",
    "    validation = train.sample(frac = 0.2)\n",
    "\n",
    "    # make sure validation data does not include training data\n",
    "    train = train[~train['filename'].isin(list(validation['filename']))]\n",
    "\n",
    "    # copy the images according to the fold\n",
    "    copy_images(train, 'training')\n",
    "    copy_images(validation, 'validation')\n",
    "    copy_images(test, 'test')\n",
    "\n",
    "    print('**** Running fold '+ str(i))\n",
    "\n",
    "    # here you call a function to create and train your model, returning validation accuracy and validation loss\n",
    "    history = History()\n",
    "    history = train_model()\n",
    "    val_accuracy = history[val_acc]\n",
    "    val_loss = history[val_loss]\n",
    "\n",
    "    # append validation accuracy and loss for average calculation later on\n",
    "    total_val_accuracy.append(val_accuracy)\n",
    "    total_val_loss.append(val_loss)\n",
    "\n",
    "    # here you will call a predict() method that will predict the images on the \"test\" subfolder \n",
    "    # this function returns the actual classes and the predicted classes in the same order\n",
    "#    total_test_images = len(x_test)\n",
    "#    actual, predicted = predict()\n",
    "\n",
    "    # append accuracy from the predictions on the test data\n",
    "#    total_test_accuracy.append(accuracy_score(actual, predicted))\n",
    "\n",
    "    # append all of the actual and predicted classes for your final evaluation\n",
    "#    total_actual = total_actual + actual\n",
    "#    total_predicted = total_predicted + predicted\n",
    "\n",
    "    # this is optional, but you can also see the performance on each fold as the process goes on\n",
    "#    print(classification_report(total_actual, total_predicted))\n",
    "#    print(confusion_matrix(total_actual, total_predicted))\n",
    "\n",
    "print(classification_report(total_actual, total_predicted))\n",
    "print(confusion_matrix(total_actual, total_predicted))\n",
    "print(\"Validation accuracy on each fold:\")\n",
    "print(total_val_accuracy)\n",
    "print(\"Mean validation accuracy: {}%\".format(np.mean(total_val_accuracy) * 100))\n",
    "\n",
    "print(\"Validation loss on each fold:\")\n",
    "print(total_val_loss)\n",
    "print(\"Mean validation loss: {}\".format(np.mean(total_val_loss)))\n",
    "\n",
    "#print(\"Test accuracy on each fold:\")\n",
    "#print(total_test_accuracy)\n",
    "#print(\"Mean test accuracy: {}%\".format(np.mean(total_test_accuracy) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
