{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "establish expected image parameters, training, validation locations\n",
    "'''\n",
    "\n",
    "# expected image size\n",
    "img_width, img_height = 256, 256\n",
    "\n",
    "# folder containing the images on which the network will train. The train folder \n",
    "# has two sub folders, 'yes' and 'no' needle-containing images.\n",
    "train_data_dir = 'data/train'\n",
    "\n",
    "# folder containing the validation samples folder structure is same as the training folder\n",
    "validation_data_dir = 'data/validation'\n",
    "\n",
    "# how many images to be considered for training\n",
    "train_samples = 504\n",
    "\n",
    "# how many images to be used for validation\n",
    "validation_samples = 63\n",
    "\n",
    "# how many runs will the network make over the training set before starting on validation\n",
    "epoch = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "build ResNet50\n",
    "'''\n",
    "\n",
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.initializers import glorot_uniform\n",
    "\n",
    "input_shape = (512, 512, 3)\n",
    "classes = 2\n",
    "\n",
    "# Define the input as a tensor with shape input_shape\n",
    "X_input = Input(input_shape)\n",
    "\n",
    "# Zero-Padding\n",
    "X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "# Stage 1\n",
    "X = Conv2D(64, (7, 7), strides = (2, 2), name = ‘conv1’,)(X)\n",
    "X = BatchNormalization(axis = 3, name = ‘bn_conv1’)(X)\n",
    "X = Activation(‘relu’)(X)\n",
    "X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "# Stage 2\n",
    "X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block=’a’, s = 1)\n",
    "X = identity_block(X, 3, [64, 64, 256], stage=2, block=’b’)\n",
    "X = identity_block(X, 3, [64, 64, 256], stage=2, block=’c’)\n",
    "\n",
    "# Stage 3\n",
    "X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block=’a’, s = 2)\n",
    "X = identity_block(X, 3, [128, 128, 512], stage=3, block=’b’)\n",
    "X = identity_block(X, 3, [128, 128, 512], stage=3, block=’c’)\n",
    "X = identity_block(X, 3, [128, 128, 512], stage=3, block=’d’)\n",
    "\n",
    "# Stage 4\n",
    "X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block=’a’, s = 2)\n",
    "X = identity_block(X, 3, [256, 256, 1024], stage=4, block=’b’)\n",
    "X = identity_block(X, 3, [256, 256, 1024], stage=4, block=’c’)\n",
    "X = identity_block(X, 3, [256, 256, 1024], stage=4, block=’d’)\n",
    "X = identity_block(X, 3, [256, 256, 1024], stage=4, block=’e’)\n",
    "X = identity_block(X, 3, [256, 256, 1024], stage=4, block=’f’)\n",
    "\n",
    "# Stage 5\n",
    "X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block=’a’, s = 2)\n",
    "X = identity_block(X, 3, [512, 512, 2048], stage=5, block=’b’)\n",
    "X = identity_block(X, 3, [512, 512, 2048], stage=5, block=’c’)\n",
    "\n",
    "# AVGPOOL\n",
    "X = AveragePooling2D((2,2), name=’avg_pool’)(X)\n",
    "\n",
    "# output layer\n",
    "X = Flatten()(X)\n",
    "X = Dense(classes, activation=’softmax’, name=’fc’ + str(classes))(X)\n",
    "\n",
    "# Create model\n",
    "model = Model(inputs = X_input, outputs = X, name=’ResNet50′)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=’adam’, loss=’categorical_crossentropy’, metrics=[‘accuracy’])\n",
    "\n",
    "# Plot the model\n",
    "plot_model(model, to_file='model.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "develop image augmentation scripts to amplify sample size\n",
    "'''\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "# generating many transformed images so that the model can handle real-world variety\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "#        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# pass images to ImageGenerator to create transformed versions\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "run model training\n",
    "'''\n",
    "\n",
    "# this is where the actual processing happens (time-consuming)\n",
    "history = model.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch=train_samples,\n",
    "        epochs=epoch,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=validation_samples)\n",
    "\n",
    "model.save_weights('trial.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
