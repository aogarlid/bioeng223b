{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "load images into python\n",
    "determine whether images are greyscale\n",
    "convert to greyscale if RGB\n",
    "file i/o to load images, matrix manipulation, standardization\n",
    "'''\n",
    "\n",
    "import PIL\n",
    "import os\n",
    "from skimage.io import imread_collection\n",
    "\n",
    "dir_name = 'data/NeedleImages/'\n",
    "imgs = []\n",
    "greyscale = []\n",
    "img_size = []\n",
    "\n",
    "# create a collection with the available images\n",
    "col = imread_collection(os.path.join(dir_name, '*.jpg'))\n",
    "# select one image for analysis\n",
    "im = col[140]\n",
    "# determine image type and shape\n",
    "print(type(im))\n",
    "print(im.shape)\n",
    "\n",
    "# create list of .jpg files in img directory\n",
    "for root, dirs, files in os.walk(dir_name):\n",
    "    for file in files:\n",
    "        if file.endswith('.jpg'):\n",
    "            imgs.append(file)\n",
    "\n",
    "# create function to test whether images are greyscale\n",
    "def is_grey_scale(img_path):\n",
    "    im = PIL.Image.open(img_path).convert('RGB')\n",
    "    w,h = im.size\n",
    "    for i in range(w):\n",
    "        for j in range(h):\n",
    "            r,g,b = im.getpixel((i,j))\n",
    "            if r != g != b:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "# test set of images for greyscale \n",
    "for i in imgs:\n",
    "    img = os.path.join(dir_name, i)\n",
    "    greyscale.append(is_grey_scale(img))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-ab5b81a5b881>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mseen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSOURCE_ROOT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "'''\n",
    "create separator to move images to folders based on labels\n",
    "'''\n",
    "\n",
    "import csv\n",
    "import os\n",
    "\n",
    "SOURCE_ROOT = 'data_base/NeedleImages'\n",
    "DEST_ROOT = 'data_base/'\n",
    "\n",
    "with open('data/labels.csv') as infile:\n",
    "    next(infile)  # Skip the header row\n",
    "    reader = csv.reader(infile)\n",
    "    seen = set()\n",
    "    for Order, External_ID, Label in reader:\n",
    "\n",
    "        src = os.path.join(SOURCE_ROOT, External_ID)\n",
    "        dest = os.path.join(DEST_ROOT, Label, External_ID)\n",
    "\n",
    "        try:\n",
    "            os.rename(src, dest)\n",
    "        except WindowsError as e:\n",
    "            print (e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "setup training, validation, testing splits\n",
    "'''\n",
    "\n",
    "yes_dir\n",
    "\n",
    "# create list of .jpg files in yes_img directory\n",
    "for root, dirs, files in os.walk(dir_name):\n",
    "    for file in files:\n",
    "        if file.endswith('.jpg'):\n",
    "            imgs.append(file)\n",
    "\n",
    "yes_filenames = ['img_000.jpg', 'img_001.jpg', ...]\n",
    "filenames.sort()  # make sure that the filenames have a fixed order before shuffling\n",
    "random.seed(42)\n",
    "random.shuffle(filenames) # shuffles the ordering of filenames (deterministic given the chosen seed)\n",
    "\n",
    "split_1 = int(0.8 * len(filenames))\n",
    "split_2 = int(0.9 * len(filenames))\n",
    "train_filenames = filenames[:split_1]\n",
    "val_filenames = filenames[split_1:split_2]\n",
    "test_filenames = filenames[split_2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "establish expected image parameters, training, validation locations\n",
    "'''\n",
    "\n",
    "# expected image size\n",
    "img_width, img_height = 512, 512\n",
    "\n",
    "# folder containing the images on which the network will train. The train folder \n",
    "# has two sub folders, 'yes' and 'no' needle-containing images.\n",
    "train_data_dir = 'data/train'\n",
    "\n",
    "# folder containing the validation samples folder structure is same as the training folder\n",
    "validation_data_dir = 'data/validation'\n",
    "\n",
    "# how many images to be considered for training\n",
    "train_samples = 2000\n",
    "\n",
    "# how many images to be used for validation\n",
    "validation_samples = 800\n",
    "\n",
    "# how many runs will the network make over the training set before starting on validation\n",
    "epoch = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "setup keras machine learning architecture\n",
    "'''\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "# ** Model Begins **\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 3, 3, input_shape=(3, img_width, img_height)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "# ** Model Ends **\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "develop image augmentation scripts to amplify sample size\n",
    "'''\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "# generating many transformed images so that the model can handle real-world variety\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# pass images to ImageGenerator to create transformed versions\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "run model training\n",
    "'''\n",
    "\n",
    "# this is where the actual processing happens (time-consuming)\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch=train_samples,\n",
    "        nb_epoch=epoch,\n",
    "        validation_data=validation_generator,\n",
    "        nb_val_samples=validation_samples)\n",
    "\n",
    "model.save_weights('trial.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
