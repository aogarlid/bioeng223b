{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "establish expected image parameters, training, validation locations\n",
    "'''\n",
    "\n",
    "# expected image size\n",
    "img_width, img_height = 256, 256\n",
    "\n",
    "# folder containing the images on which the network will train. The train folder \n",
    "# has two sub folders, 'yes' and 'no' needle-containing images.\n",
    "train_data_dir = 'data/train'\n",
    "\n",
    "# folder containing the validation samples folder structure is same as the training folder\n",
    "validation_data_dir = 'data/validation'\n",
    "\n",
    "# how many images to be considered for training\n",
    "train_samples = 504\n",
    "\n",
    "# how many images to be used for validation\n",
    "validation_samples = 62\n",
    "\n",
    "# how many runs will the network make over the training set before starting on validation\n",
    "epoch = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "setup keras machine learning architecture\n",
    "'''\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.utils import plot_model\n",
    "\n",
    "# ** Model Begins **\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, (3, 3), input_shape=(img_width, img_height, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "# ** Model Ends **\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "plot_model(model, to_file='model.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 504 images belonging to 2 classes.\n",
      "Found 62 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "develop image augmentation scripts to amplify sample size\n",
    "'''\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "# generating many transformed images so that the model can handle real-world variety\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "#        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# pass images to ImageGenerator to create transformed versions\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aogarlid/anaconda3/envs/bioeng/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., epochs=100, validation_data=<keras_pre..., validation_steps=62, steps_per_epoch=15)`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 [==============================] - 21s 1s/step - loss: 1.1208 - acc: 0.6375 - val_loss: 0.6620 - val_acc: 0.6452\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 18s 1s/step - loss: 0.6648 - acc: 0.6120 - val_loss: 0.6279 - val_acc: 0.6452\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 14s 961ms/step - loss: 0.6446 - acc: 0.6589 - val_loss: 0.6265 - val_acc: 0.6452\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 15s 995ms/step - loss: 0.6256 - acc: 0.6550 - val_loss: 0.6550 - val_acc: 0.6452\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 14s 906ms/step - loss: 0.5702 - acc: 0.6993 - val_loss: 0.6136 - val_acc: 0.6452\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 14s 964ms/step - loss: 0.6096 - acc: 0.6951 - val_loss: 0.6162 - val_acc: 0.6613\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 14s 946ms/step - loss: 0.5359 - acc: 0.7089 - val_loss: 0.6414 - val_acc: 0.6613\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 15s 967ms/step - loss: 0.6025 - acc: 0.6979 - val_loss: 0.6011 - val_acc: 0.6774\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 14s 963ms/step - loss: 0.5167 - acc: 0.7702 - val_loss: 0.7225 - val_acc: 0.6613\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 14s 923ms/step - loss: 0.5414 - acc: 0.7465 - val_loss: 0.6514 - val_acc: 0.6774\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 14s 931ms/step - loss: 0.4832 - acc: 0.7890 - val_loss: 0.6582 - val_acc: 0.6290\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 14s 966ms/step - loss: 0.4729 - acc: 0.7855 - val_loss: 0.6746 - val_acc: 0.6774\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 14s 954ms/step - loss: 0.4201 - acc: 0.8008 - val_loss: 0.8519 - val_acc: 0.5968\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 14s 955ms/step - loss: 0.4145 - acc: 0.8076 - val_loss: 0.6989 - val_acc: 0.6613\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 14s 924ms/step - loss: 0.3688 - acc: 0.8306 - val_loss: 0.7425 - val_acc: 0.6452\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 14s 941ms/step - loss: 0.3458 - acc: 0.8485 - val_loss: 0.7077 - val_acc: 0.6613\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 15s 981ms/step - loss: 0.2987 - acc: 0.8896 - val_loss: 0.8519 - val_acc: 0.5806\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 14s 929ms/step - loss: 0.2639 - acc: 0.8938 - val_loss: 1.0322 - val_acc: 0.6774\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 15s 977ms/step - loss: 0.2777 - acc: 0.8889 - val_loss: 0.9424 - val_acc: 0.6452\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 14s 927ms/step - loss: 0.2185 - acc: 0.9264 - val_loss: 1.0381 - val_acc: 0.6935\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 16s 1s/step - loss: 0.1886 - acc: 0.9340 - val_loss: 1.1238 - val_acc: 0.7258\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 15s 987ms/step - loss: 0.1423 - acc: 0.9486 - val_loss: 0.9507 - val_acc: 0.6774\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 16s 1s/step - loss: 0.1737 - acc: 0.9347 - val_loss: 1.0667 - val_acc: 0.7258\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 15s 986ms/step - loss: 0.1190 - acc: 0.9493 - val_loss: 1.0446 - val_acc: 0.6935\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 15s 990ms/step - loss: 0.1045 - acc: 0.9702 - val_loss: 1.1042 - val_acc: 0.6129\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 14s 911ms/step - loss: 0.1130 - acc: 0.9562 - val_loss: 1.3282 - val_acc: 0.7258\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 15s 973ms/step - loss: 0.0922 - acc: 0.9660 - val_loss: 1.4693 - val_acc: 0.6774\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 14s 906ms/step - loss: 0.0817 - acc: 0.9674 - val_loss: 1.4265 - val_acc: 0.7097\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 15s 967ms/step - loss: 0.0847 - acc: 0.9812 - val_loss: 1.5102 - val_acc: 0.6774\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 15s 984ms/step - loss: 0.0790 - acc: 0.9681 - val_loss: 1.6103 - val_acc: 0.6935\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 14s 962ms/step - loss: 0.0521 - acc: 0.9771 - val_loss: 1.8971 - val_acc: 0.5968\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 15s 1s/step - loss: 0.0562 - acc: 0.9806 - val_loss: 1.6846 - val_acc: 0.6935\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 15s 984ms/step - loss: 0.0704 - acc: 0.9792 - val_loss: 1.8374 - val_acc: 0.7097\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 16s 1s/step - loss: 0.0993 - acc: 0.9666 - val_loss: 1.4888 - val_acc: 0.6452\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 16s 1s/step - loss: 0.0347 - acc: 0.9917 - val_loss: 1.3479 - val_acc: 0.6774\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 14s 936ms/step - loss: 0.0254 - acc: 0.9910 - val_loss: 1.4567 - val_acc: 0.6452\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 14s 923ms/step - loss: 0.0402 - acc: 0.9791 - val_loss: 2.0455 - val_acc: 0.7419\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 14s 922ms/step - loss: 0.0363 - acc: 0.9848 - val_loss: 1.5245 - val_acc: 0.7097\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 15s 1s/step - loss: 0.0213 - acc: 0.9958 - val_loss: 2.1302 - val_acc: 0.6935\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 14s 956ms/step - loss: 0.0344 - acc: 0.9854 - val_loss: 1.7260 - val_acc: 0.6935\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 15s 972ms/step - loss: 0.0192 - acc: 0.9958 - val_loss: 1.8818 - val_acc: 0.7097\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 13s 878ms/step - loss: 0.0300 - acc: 0.9896 - val_loss: 2.1108 - val_acc: 0.6774\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 15s 980ms/step - loss: 0.0181 - acc: 0.9917 - val_loss: 1.7729 - val_acc: 0.7419\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 14s 961ms/step - loss: 0.0572 - acc: 0.9812 - val_loss: 1.7576 - val_acc: 0.6935\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 14s 944ms/step - loss: 0.0244 - acc: 0.9917 - val_loss: 1.9550 - val_acc: 0.7097\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 15s 981ms/step - loss: 0.0339 - acc: 0.9875 - val_loss: 1.9591 - val_acc: 0.6774\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 14s 955ms/step - loss: 0.0164 - acc: 0.9937 - val_loss: 2.1846 - val_acc: 0.6613\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 15s 969ms/step - loss: 0.0210 - acc: 0.9917 - val_loss: 2.5145 - val_acc: 0.7097\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 15s 991ms/step - loss: 0.0227 - acc: 0.9875 - val_loss: 2.1709 - val_acc: 0.5806\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 14s 951ms/step - loss: 0.0651 - acc: 0.9812 - val_loss: 1.6696 - val_acc: 0.6452\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 13s 893ms/step - loss: 0.0347 - acc: 0.9854 - val_loss: 1.8424 - val_acc: 0.6613\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 15s 972ms/step - loss: 0.0371 - acc: 0.9889 - val_loss: 1.9180 - val_acc: 0.7258\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 14s 951ms/step - loss: 0.0148 - acc: 0.9937 - val_loss: 2.2848 - val_acc: 0.7419\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 14s 966ms/step - loss: 0.0145 - acc: 0.9958 - val_loss: 2.1590 - val_acc: 0.7258\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 14s 945ms/step - loss: 0.0328 - acc: 0.9833 - val_loss: 1.7317 - val_acc: 0.7258\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 15s 980ms/step - loss: 0.0241 - acc: 0.9875 - val_loss: 1.8636 - val_acc: 0.7097\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 15s 967ms/step - loss: 0.0253 - acc: 0.9917 - val_loss: 2.1314 - val_acc: 0.7258\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 14s 958ms/step - loss: 0.0090 - acc: 0.9917 - val_loss: 2.3890 - val_acc: 0.7258\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 14s 928ms/step - loss: 0.0138 - acc: 0.9952 - val_loss: 2.1602 - val_acc: 0.7097\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 15s 988ms/step - loss: 0.0280 - acc: 0.9917 - val_loss: 1.9335 - val_acc: 0.7258\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 14s 966ms/step - loss: 0.0057 - acc: 0.9979 - val_loss: 2.4849 - val_acc: 0.6613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "15/15 [==============================] - 14s 959ms/step - loss: 0.0220 - acc: 0.9917 - val_loss: 2.2712 - val_acc: 0.7258\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 15s 1s/step - loss: 0.0320 - acc: 0.9958 - val_loss: 2.5461 - val_acc: 0.5645\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 14s 954ms/step - loss: 0.0287 - acc: 0.9910 - val_loss: 3.2989 - val_acc: 0.6774\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 14s 966ms/step - loss: 0.0177 - acc: 0.9917 - val_loss: 2.2372 - val_acc: 0.6613\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 14s 945ms/step - loss: 0.0216 - acc: 0.9937 - val_loss: 2.8390 - val_acc: 0.6935\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 14s 961ms/step - loss: 0.0085 - acc: 0.9979 - val_loss: 2.2287 - val_acc: 0.7258\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 14s 942ms/step - loss: 0.0542 - acc: 0.9868 - val_loss: 2.4033 - val_acc: 0.6290\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 14s 964ms/step - loss: 0.0161 - acc: 0.9937 - val_loss: 2.2703 - val_acc: 0.6613\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 15s 974ms/step - loss: 0.0087 - acc: 0.9958 - val_loss: 2.1878 - val_acc: 0.6774\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 14s 956ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 2.9363 - val_acc: 0.7097\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 15s 982ms/step - loss: 9.2995e-04 - acc: 1.0000 - val_loss: 2.5794 - val_acc: 0.7258\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 15s 1s/step - loss: 0.0909 - acc: 0.9729 - val_loss: 2.6932 - val_acc: 0.7581\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 14s 935ms/step - loss: 0.0097 - acc: 0.9979 - val_loss: 2.2701 - val_acc: 0.7258\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 15s 975ms/step - loss: 0.0071 - acc: 0.9958 - val_loss: 2.9093 - val_acc: 0.7258\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 14s 953ms/step - loss: 0.0183 - acc: 0.9917 - val_loss: 2.8938 - val_acc: 0.6935\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 14s 955ms/step - loss: 0.0070 - acc: 0.9979 - val_loss: 2.4375 - val_acc: 0.7097\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 14s 905ms/step - loss: 0.0178 - acc: 0.9910 - val_loss: 2.1908 - val_acc: 0.7097\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 14s 958ms/step - loss: 0.0419 - acc: 0.9883 - val_loss: 1.8180 - val_acc: 0.7097\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 15s 971ms/step - loss: 0.0065 - acc: 0.9973 - val_loss: 1.7942 - val_acc: 0.7097\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 15s 975ms/step - loss: 0.0109 - acc: 0.9958 - val_loss: 1.9263 - val_acc: 0.7097\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 15s 975ms/step - loss: 0.0026 - acc: 0.9979 - val_loss: 2.3333 - val_acc: 0.7258\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 15s 998ms/step - loss: 0.0102 - acc: 0.9958 - val_loss: 3.2034 - val_acc: 0.6774\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 14s 961ms/step - loss: 0.0103 - acc: 0.9958 - val_loss: 2.8149 - val_acc: 0.6290\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 14s 958ms/step - loss: 0.0059 - acc: 0.9979 - val_loss: 2.5416 - val_acc: 0.6452\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 15s 987ms/step - loss: 0.0202 - acc: 0.9979 - val_loss: 2.5182 - val_acc: 0.6774\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 15s 982ms/step - loss: 0.0072 - acc: 0.9979 - val_loss: 2.5405 - val_acc: 0.7097\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 14s 963ms/step - loss: 0.0056 - acc: 0.9979 - val_loss: 2.2083 - val_acc: 0.7097\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 15s 970ms/step - loss: 0.0690 - acc: 0.9716 - val_loss: 2.5376 - val_acc: 0.7258\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 14s 944ms/step - loss: 0.0109 - acc: 0.9937 - val_loss: 2.2322 - val_acc: 0.7097\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 15s 1s/step - loss: 0.0165 - acc: 0.9958 - val_loss: 2.1935 - val_acc: 0.6935\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 15s 1s/step - loss: 0.0015 - acc: 1.0000 - val_loss: 2.6093 - val_acc: 0.7097\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 14s 956ms/step - loss: 0.0413 - acc: 0.9937 - val_loss: 2.1954 - val_acc: 0.7258\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 14s 962ms/step - loss: 0.0088 - acc: 0.9979 - val_loss: 2.3906 - val_acc: 0.6935\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 14s 963ms/step - loss: 0.0072 - acc: 0.9979 - val_loss: 2.1361 - val_acc: 0.6935\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 14s 920ms/step - loss: 0.0153 - acc: 0.9917 - val_loss: 2.4454 - val_acc: 0.7258\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 15s 974ms/step - loss: 0.0205 - acc: 0.9958 - val_loss: 1.8536 - val_acc: 0.7258\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 16s 1s/step - loss: 0.0062 - acc: 1.0000 - val_loss: 2.5120 - val_acc: 0.6452\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 15s 1s/step - loss: 0.0028 - acc: 1.0000 - val_loss: 2.3019 - val_acc: 0.7258\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 17s 1s/step - loss: 6.8529e-04 - acc: 1.0000 - val_loss: 2.0576 - val_acc: 0.7581\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "run model training\n",
    "'''\n",
    "\n",
    "# this is where the actual processing happens (time-consuming)\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch=train_samples,\n",
    "        epochs=epoch,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=validation_samples)\n",
    "\n",
    "model.save_weights('trial.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training history visualization\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history = model.fit(x, y, validation_split=0.1095, epochs=100, batch_size=32, verbose=1)\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-cc670e870462>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# list all data in history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# summarize history for accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "# Visualize training history\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial.h5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "# path to the model weights files.\n",
    "weights_path = 'vgg16_weights.h5'\n",
    "top_model_weights_path = 'fc_model.h5'\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 256, 256\n",
    "\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "epochs = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the VGG16 network\n",
    "model = Sequential()\n",
    "model.add(ZeroPadding2D((1, 1), input_shape=(3, img_width, img_height)))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_2'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_2'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_2'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_3'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_2'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_3'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_2'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_3'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "# load the weights of the VGG16 networks\n",
    "# (trained on ImageNet, won the ILSVRC competition in 2014)\n",
    "# note: when there is a complete match between your model definition\n",
    "# and your weight savefile, you can simply call model.load_weights(filename)\n",
    "assert os.path.exists(weights_path), 'Model weights not found (see \"weights_path\" variable in script).'\n",
    "f = h5py.File(weights_path)\n",
    "for k in range(f.attrs['nb_layers']):\n",
    "    if k >= len(model.layers):\n",
    "        # we don't look at the last (fully-connected) layers in the savefile\n",
    "        break\n",
    "    g = f['layer_{}'.format(k)]\n",
    "    weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]\n",
    "    model.layers[k].set_weights(weights)\n",
    "f.close()\n",
    "print('Model loaded.')\n",
    "\n",
    "# build a classifier model to put on top of the convolutional model\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# note that it is necessary to start with a fully-trained\n",
    "# classifier, including the top classifier,\n",
    "# in order to successfully do fine-tuning\n",
    "top_model.load_weights(top_model_weights_path)\n",
    "\n",
    "# add the model on top of the convolutional base\n",
    "model.add(top_model)\n",
    "\n",
    "# set the first 25 layers (up to the last conv block)\n",
    "# to non-trainable (weights will not be updated)\n",
    "for layer in model.layers[:25]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model with a SGD/momentum optimizer\n",
    "# and a very slow learning rate.\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "# fine-tune the model\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch=nb_train_samples,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_validation_samples)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
