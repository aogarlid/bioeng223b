{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(512, 512)\n",
      "<class 'numpy.ndarray'>\n",
      "(512, 512)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "load images into python\n",
    "determine whether images are greyscale\n",
    "convert to greyscale if RGB\n",
    "file i/o to load images, matrix manipulation, standardization\n",
    "'''\n",
    "\n",
    "import PIL\n",
    "import os\n",
    "from skimage.io import imread_collection\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "dir_name = 'data_base/backup/NeedleImages/'\n",
    "imgs = []\n",
    "greyscale = []\n",
    "img_size = []\n",
    "\n",
    "# create a collection with the available images\n",
    "col = imread_collection(os.path.join(dir_name, '*.jpg'))\n",
    "# select one image for analysis\n",
    "im = col[140]\n",
    "\n",
    "# determine image type and shape\n",
    "print(type(im))\n",
    "print(im.shape)\n",
    "\n",
    "img_gray = rgb2gray(im)\n",
    "# determine gray image type and shape\n",
    "print(type(img_gray))\n",
    "print(img_gray.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list .jpg files in img directory\n",
    "for root, dirs, files in os.walk(dir_name):\n",
    "    for file in files:\n",
    "        if file.endswith('.jpg'):\n",
    "            imgs.append(file)\n",
    "\n",
    "# create function to test whether images are greyscale\n",
    "def is_grey_scale(img_path):\n",
    "    im = PIL.Image.open(img_path).convert('RGB')\n",
    "    w,h = im.size\n",
    "    for i in range(w):\n",
    "        for j in range(h):\n",
    "            r,g,b = im.getpixel((i,j))\n",
    "            if r != g != b:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "# test set of images for greyscale \n",
    "for i in imgs:\n",
    "    img = os.path.join(dir_name, i)\n",
    "    greyscale.append(is_grey_scale(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "create separator to move images to folders based on labels\n",
    "'''\n",
    "\n",
    "import csv\n",
    "import os\n",
    "\n",
    "SOURCE_ROOT = 'data_base/NeedleImages'\n",
    "DEST_ROOT = 'data_base/'\n",
    "\n",
    "with open('data/labels.csv') as infile:\n",
    "    next(infile)  # Skip the header row\n",
    "    reader = csv.reader(infile)\n",
    "    seen = set()\n",
    "    for Order, External_ID, Label in reader:\n",
    "        src = os.path.join(SOURCE_ROOT, External_ID)\n",
    "        dest = os.path.join(DEST_ROOT, Label, External_ID)\n",
    "        try:\n",
    "            os.rename(src, dest)\n",
    "        except WindowsError as e:\n",
    "            print (e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "setup training, validation, testing splits\n",
    "'''\n",
    "\n",
    "import random\n",
    "\n",
    "yes_dir = 'data_base/yes'\n",
    "no_dir = 'data_base/no'\n",
    "yes_imgs = []\n",
    "no_imgs = []\n",
    "\n",
    "# create list of .jpg files in yes_img directory\n",
    "for root, dirs, files in os.walk(yes_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.jpg'):\n",
    "            yes_imgs.append(file)\n",
    "\n",
    "yes_imgs.sort()  # make sure that the filenames have a fixed order before shuffling\n",
    "random.seed(42)\n",
    "random.shuffle(yes_imgs) # shuffles the ordering of filenames (deterministic given the chosen seed)\n",
    "\n",
    "split_1 = int(0.8 * len(yes_imgs))\n",
    "split_2 = int(0.9 * len(yes_imgs))\n",
    "train_filenames = yes_imgs[:split_1]\n",
    "val_filenames = yes_imgs[split_1:split_2]\n",
    "test_filenames = yes_imgs[split_2:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of .jpg files in no_img directory\n",
    "for root, dirs, files in os.walk(no_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.jpg'):\n",
    "            no_imgs.append(file)\n",
    "\n",
    "no_imgs.sort()  # make sure that the filenames have a fixed order before shuffling\n",
    "random.seed(42)\n",
    "random.shuffle(no_imgs) # shuffles the ordering of filenames (deterministic given the chosen seed)\n",
    "\n",
    "split_1 = int(0.8 * len(no_imgs))\n",
    "split_2 = int(0.9 * len(no_imgs))\n",
    "no_train_filenames = no_imgs[:split_1]\n",
    "no_val_filenames = no_imgs[split_1:split_2]\n",
    "no_test_filenames = no_imgs[split_2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "create function to move images to appropriate folder for training, validation, and testing\n",
    "'''\n",
    "\n",
    "def move_images(img_list, src_dir, dest_dir):\n",
    "    for img in img_list:\n",
    "        src = os.path.join(src_dir, img)\n",
    "        dest = os.path.join(dest_dir, img)\n",
    "        os.rename(src, dest)\n",
    "\n",
    "# move yes training data\n",
    "move_images(train_filenames, 'data_base/yes/', 'data/train/yes/')\n",
    "# move no training data\n",
    "move_images(no_train_filenames, 'data_base/no/', 'data/train/no/')\n",
    "\n",
    "# move testing data\n",
    "move_images(test_filenames, 'data_base/yes/', 'data/test/yes/')\n",
    "# move no testing data\n",
    "move_images(no_test_filenames, 'data_base/no/', 'data/test/no/')\n",
    "\n",
    "# move validation data\n",
    "move_images(val_filenames, 'data_base/yes/', 'data/validation/yes/')\n",
    "# move no validation data\n",
    "move_images(no_val_filenames, 'data_base/no/', 'data/validation/no/')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "establish expected image parameters, training, validation locations\n",
    "'''\n",
    "\n",
    "# expected image size\n",
    "img_width, img_height = 512, 512\n",
    "\n",
    "# folder containing the images on which the network will train. The train folder \n",
    "# has two sub folders, 'yes' and 'no' needle-containing images.\n",
    "train_data_dir = 'data/train'\n",
    "\n",
    "# folder containing the validation samples folder structure is same as the training folder\n",
    "validation_data_dir = 'data/validation'\n",
    "\n",
    "# how many images to be considered for training\n",
    "train_samples = 1800\n",
    "\n",
    "# how many images to be used for validation\n",
    "validation_samples = 200\n",
    "\n",
    "# how many runs will the network make over the training set before starting on validation\n",
    "epoch = 15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "setup keras machine learning architecture\n",
    "'''\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "# ** Model Begins **\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, (3, 3), input_shape=(img_width, img_height, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "# ** Model Ends **\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 504 images belonging to 2 classes.\n",
      "Found 62 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "develop image augmentation scripts to amplify sample size\n",
    "'''\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "# generating many transformed images so that the model can handle real-world variety\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# pass images to ImageGenerator to create transformed versions\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., epochs=15, validation_data=<keras_pre..., validation_steps=200, steps_per_epoch=56)`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "56/56 [==============================] - 234s 4s/step - loss: 1.3869 - acc: 0.6306 - val_loss: 0.6293 - val_acc: 0.6452\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 231s 4s/step - loss: 0.5910 - acc: 0.6892 - val_loss: 0.6837 - val_acc: 0.6129\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 227s 4s/step - loss: 0.5649 - acc: 0.7085 - val_loss: 0.6435 - val_acc: 0.6774\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 232s 4s/step - loss: 0.5329 - acc: 0.7277 - val_loss: 0.6534 - val_acc: 0.6452\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 226s 4s/step - loss: 0.5332 - acc: 0.7249 - val_loss: 0.6944 - val_acc: 0.6129\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 223s 4s/step - loss: 0.4889 - acc: 0.7608 - val_loss: 0.6523 - val_acc: 0.6613\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 224s 4s/step - loss: 0.4685 - acc: 0.7799 - val_loss: 0.7110 - val_acc: 0.6613\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 225s 4s/step - loss: 0.4409 - acc: 0.7922 - val_loss: 0.7152 - val_acc: 0.6290\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 224s 4s/step - loss: 0.4140 - acc: 0.8117 - val_loss: 0.7279 - val_acc: 0.6452\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 225s 4s/step - loss: 0.3911 - acc: 0.8270 - val_loss: 0.8142 - val_acc: 0.6290\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 226s 4s/step - loss: 0.3882 - acc: 0.8289 - val_loss: 0.7076 - val_acc: 0.6290\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 225s 4s/step - loss: 0.3597 - acc: 0.8412 - val_loss: 0.8260 - val_acc: 0.6613\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 226s 4s/step - loss: 0.3382 - acc: 0.8449 - val_loss: 0.8102 - val_acc: 0.6452\n",
      "Epoch 14/15\n",
      "56/56 [==============================] - 226s 4s/step - loss: 0.3265 - acc: 0.8542 - val_loss: 1.0213 - val_acc: 0.6452\n",
      "Epoch 15/15\n",
      "56/56 [==============================] - 225s 4s/step - loss: 0.3113 - acc: 0.8588 - val_loss: 1.0032 - val_acc: 0.6452\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "run model training\n",
    "'''\n",
    "\n",
    "# this is where the actual processing happens (time-consuming)\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch=train_samples,\n",
    "        epochs=epoch,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=validation_samples)\n",
    "\n",
    "model.save_weights('trial.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial.h5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "# path to the model weights files.\n",
    "weights_path = 'vgg16_weights.h5'\n",
    "top_model_weights_path = 'fc_model.h5'\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 256, 256\n",
    "\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "epochs = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the VGG16 network\n",
    "model = Sequential()\n",
    "model.add(ZeroPadding2D((1, 1), input_shape=(3, img_width, img_height)))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_2'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_2'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_2'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_3'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_2'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_3'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_2'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_3'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "# load the weights of the VGG16 networks\n",
    "# (trained on ImageNet, won the ILSVRC competition in 2014)\n",
    "# note: when there is a complete match between your model definition\n",
    "# and your weight savefile, you can simply call model.load_weights(filename)\n",
    "assert os.path.exists(weights_path), 'Model weights not found (see \"weights_path\" variable in script).'\n",
    "f = h5py.File(weights_path)\n",
    "for k in range(f.attrs['nb_layers']):\n",
    "    if k >= len(model.layers):\n",
    "        # we don't look at the last (fully-connected) layers in the savefile\n",
    "        break\n",
    "    g = f['layer_{}'.format(k)]\n",
    "    weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]\n",
    "    model.layers[k].set_weights(weights)\n",
    "f.close()\n",
    "print('Model loaded.')\n",
    "\n",
    "# build a classifier model to put on top of the convolutional model\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# note that it is necessary to start with a fully-trained\n",
    "# classifier, including the top classifier,\n",
    "# in order to successfully do fine-tuning\n",
    "top_model.load_weights(top_model_weights_path)\n",
    "\n",
    "# add the model on top of the convolutional base\n",
    "model.add(top_model)\n",
    "\n",
    "# set the first 25 layers (up to the last conv block)\n",
    "# to non-trainable (weights will not be updated)\n",
    "for layer in model.layers[:25]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model with a SGD/momentum optimizer\n",
    "# and a very slow learning rate.\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "# fine-tune the model\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch=nb_train_samples,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_validation_samples)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
